# üéôÔ∏è VoxFlow: Natural Multiplatform TTS

**VoxFlow** es una soluci√≥n de s√≠ntesis de voz (Text-to-Speech) basada en modelos neuronales de √∫ltima generaci√≥n. El objetivo principal es proporcionar voces humanas extremadamente naturales que funcionen de forma local y privada en cualquier sistema operativo.

---

## üöÄ Caracter√≠sticas Principales

- **Naturalidad Superior:** Utiliza modelos VITS para una entonaci√≥n humana.
- **Multiplataforma:** Soporte nativo para Windows, Android, Linux y macOS.
- **Privacidad Total:** Funciona 100% offline. No se env√≠an datos a la nube.
- **Alto Rendimiento:** Optimizado incluso para hardware modesto como Raspberry Pi o dispositivos Android antiguos.

---

## üõ†Ô∏è Instalaci√≥n

Para configurar el entorno de desarrollo, sigue estos pasos:

### Requisitos previos
- Python 3.10 o superior.
- Pip (gestor de paquetes de Python).

### Pasos
1. **Clonar el repositorio:**
   ```bash
   git clone [https://github.com/tu-usuario/VoxFlow.git](https://github.com/tu-usuario/VoxFlow.git)
   cd VoxFlow
Instalar dependencias:

Bash

pip install -r requirements.txt
Descargar un modelo de voz: Descarga un archivo .onnx desde el cat√°logo de Piper Voices y col√≥calo en la carpeta ra√≠z del proyecto.

üíª Ejemplo de Uso
El n√∫cleo del proyecto est√° dise√±ado para ser simple y profesional:

Python

# Importamos la l√≥gica principal del sintetizador
from voxflow_core import Synthesizer

# Inicializamos el motor con el modelo descargado
# El modelo debe ser un archivo .onnx perfectamente configurado
engine = Synthesizer(model_path="es_ES-sharvard-medium.onnx")

# Convertimos texto a voz de manera inmediata
# La funci√≥n 'play' gestiona la salida de audio seg√∫n el OS
engine.say("Hola, bienvenido al futuro de la s√≠ntesis de voz natural.")
üì± Compilaci√≥n para M√≥vil y Escritorio
Este proyecto utiliza Flet para la interfaz gr√°fica, lo que permite empaquetar la app f√°cilmente:

Para Android: flet build apk

Para Windows: flet build windows

Para macOS: flet build macos

üìÑ Licencia
Este proyecto est√° bajo la Licencia MIT. Consulta el archivo LICENSE para m√°s detalles.

ü§ù Contribuciones
¬°Las contribuciones son bienvenidas! Si tienes ideas para mejorar la naturalidad o a√±adir nuevos idiomas, abre un Pull Request o una Issue.


---

### 4. Resumen del c√≥digo de l√≥gica (`voxflow_core.py`)
Para que tu proyecto est√© completo, aqu√≠ tienes la clase base comentada l√≠nea a l√≠nea:

```python
import subprocess # M√≥dulo para ejecutar procesos del sistema operativo
import platform   # Para detectar si estamos en Windows, Linux o Mac

class Synthesizer:
    # M√©todo constructor para inicializar la ruta del modelo de voz
    def __init__(self, model_path):
        self.model_path = model_path # Guardamos la ruta del archivo .onnx

    # M√©todo para procesar texto y convertirlo en audio audible
    def say(self, text):
        # Detectamos el sistema operativo actual del usuario
        os_type = platform.system()

        # Construimos el comando base de Piper con el modelo especificado
        # Piper recibe texto por entrada est√°ndar (stdin) y devuelve audio raw
        base_cmd = f'echo "{text}" | piper --model {self.model_path} --output_raw'

        # Ajustamos el comando de reproducci√≥n seg√∫n el sistema operativo detectado
        if os_type == "Linux" or os_type == "Darwin": # Darwin es el n√∫cleo de macOS
            # En sistemas Unix usamos 'aplay' o 'afplay' para reproducir el audio raw
            full_cmd = f"{base_cmd} | aplay -r 22050 -f S16_LE -t raw"
        elif os_type == "Windows":
            # En Windows se suele redirigir a un reproductor compatible como ffplay
            full_cmd = f"{base_cmd} | ffplay -ar 22050 -f s16le -nodisp -autoexit -"
        
        # Ejecutamos el comando final en una shell del sistema de forma segura
        subprocess.Popen(full_cmd, shell=True)
